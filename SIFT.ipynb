{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting frames from the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, skip_frames):\n",
    "    # it reads video from the specified path\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    video_dir = os.path.dirname(video_path)\n",
    "    \n",
    "    frame_idx = 0 \n",
    "    saved_frame_idx = 0  \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # frame_idx is multiple of skip_frames which means we are at the frame that we wanna save\n",
    "        if ret and frame_idx % skip_frames == 0:\n",
    "            # naming the images like this : image0, image1 ...etc that's why we are using saved_frame_idx\n",
    "            frame_path = os.path.join(video_dir, f\"output_frame_{saved_frame_idx:04d}.png\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            saved_frame_idx += 1\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_idx += 1\n",
    "    \n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "video_path = 'videos/physics/VID_20240407_163112.mp4'  # Make sure to adjust this path\n",
    "skip_frames = 10  # Adjust this based on your video and how much overlap you want\n",
    "extract_frames(video_path, skip_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating panoramic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def create_panorama(image_folder, save_folder):\n",
    "    images = []\n",
    "    #i used sorted to make sure the images will be uploaded in the correct order\n",
    "    for filename in sorted(os.listdir(image_folder)):\n",
    "        img = cv2.imread(os.path.join(image_folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    \n",
    "\n",
    "    if len(images) < 2:\n",
    "        print(\"Need at least two images to create a panorama.\")\n",
    "        return\n",
    "    \n",
    "    stitcher = cv2.Stitcher_create()\n",
    "    # 1- Initialization\n",
    "    # 2- Feature detection -> SIFT\n",
    "    # 3- Feature matching -> FLANN\n",
    "    # 4- Estimate camera parameters with enough images -> homography estimation\n",
    "    # 5- Image warping and alignment ->  perspective transformation\n",
    "    # 6- Blending to smooth them -> Multi-band blending\n",
    "    status, panorama = stitcher.stitch(images)\n",
    "    \n",
    "    # if stitching successful\n",
    "    if status == cv2.Stitcher_OK:\n",
    "        cv2.imshow(\"Panorama\", panorama)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "\n",
    "        save_path = os.path.join(save_folder, 'panorama.jpg')\n",
    "        cv2.imwrite(save_path, panorama)\n",
    "        print(f\"Panorama saved to {save_path}\")\n",
    "    else:\n",
    "        print(\"Error during stitching: \", status)\n",
    "\n",
    "image_folder = \"videos/physics\"\n",
    "save_folder = \"data/Place4\"\n",
    "create_panorama(image_folder, save_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping to remove stitching errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def crop_and_save_image(image_path):\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image {image_path}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # if image is larg enough\n",
    "    if h > 40 and w > 40:\n",
    "        cropped_image = image[130:h-130, 130:w-130]\n",
    "        save_path = os.path.join(os.path.dirname(image_path), 'cropped_' + os.path.basename(image_path))\n",
    "        cv2.imwrite(save_path, cropped_image)\n",
    "        print(f\"Cropped image saved to {save_path}\")\n",
    "    else:\n",
    "        print(\"Image is too small to crop 20 pixels from each side.\")\n",
    "\n",
    "image_path = 'data/Place4/panorama.jpg'  \n",
    "crop_and_save_image(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT file for all 4 places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "dataset_path = 'data'\n",
    "\n",
    "places_features = {}\n",
    "for place in os.listdir(dataset_path):\n",
    "    place_path = os.path.join(dataset_path, place)\n",
    "    if not os.path.isdir(place_path):\n",
    "        continue\n",
    "\n",
    "    images = [img for img in os.listdir(place_path) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    descriptors_list = []\n",
    "\n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(place_path, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Bcz SIFT works with grayscal images\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "        if descriptors is not None:\n",
    "            descriptors_list.append(descriptors)\n",
    "\n",
    "    \n",
    "    if descriptors_list:\n",
    "        #this vstack to make sure that descriptors of each place are saved together as a single array, then we store this array in places_features\n",
    "        combined_descriptors = np.vstack(descriptors_list)\n",
    "        places_features[place] = combined_descriptors\n",
    "\n",
    "np.savez('saved_sift_features.npz', **places_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we can add : Detectron2 to classify images wether they are gonna be used for SIFT or for map reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most similar place according to SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import folium\n",
    "import os\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "def load_place_metadata(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_best_match_coordinates(best_match_place, places_metadata):\n",
    "    for place in places_metadata:\n",
    "        if place['name'] == best_match_place:\n",
    "            return place['coordinates']\n",
    "    return None\n",
    "\n",
    "def find_best_match(query_image_path, data):\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    if query_image is None:\n",
    "        raise ValueError(f\"Cannot read image at {query_image_path}\")\n",
    "    query_gray = cv2.cvtColor(query_image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    _, query_descriptors = sift.detectAndCompute(query_gray, None)\n",
    "    # 1- KD-tree as algorithms it uses nearest neighbor search \n",
    "    # 2- search for 2 NN (k=2) for each descriptor \n",
    "    # 3- distance to the nearest neighbor is less than 75% of the distance to the second nearest neighbor -> it's a good match\n",
    "    # 4- place with the highest number of good matches is most similar place\n",
    "    flann = cv2.FlannBasedMatcher({'algorithm': 1, 'trees': 5}, {'checks': 50})\n",
    "    max_matches = 0\n",
    "    best_match_place = None\n",
    "    for place_name in data.files:\n",
    "        place_descriptors = data[place_name]\n",
    "        matches = flann.knnMatch(query_descriptors, place_descriptors, k=2)\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "        if len(good_matches) > max_matches:\n",
    "            max_matches = len(good_matches)\n",
    "            best_match_place = place_name\n",
    "    return best_match_place\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query_folder = 'Query/math/sift'\n",
    "    data = np.load('saved_sift_features.npz', allow_pickle=True)\n",
    "    places_metadata = load_place_metadata('places_metadata.json')\n",
    "    results = Counter()\n",
    "\n",
    "    for query_image_name in os.listdir(query_folder):\n",
    "        query_image_path = os.path.join(query_folder, query_image_name)\n",
    "        try:\n",
    "            best_match_place = find_best_match(query_image_path, data)\n",
    "            # save how many times each place was identified as a match across all query images\n",
    "            results[best_match_place] += 1\n",
    "            print(f\"The most similar place for image {query_image_name} is {best_match_place}\")\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "\n",
    "    if results:\n",
    "        # most frequently occurring place in the results\n",
    "        most_common_place, _ = results.most_common(1)[0]\n",
    "        print(f\"According to the voting, the most similar place is {most_common_place}\")\n",
    "        best_match_coordinates = get_best_match_coordinates(most_common_place, places_metadata)\n",
    "        if best_match_coordinates:\n",
    "            m = folium.Map(location=[best_match_coordinates['latitude'], best_match_coordinates['longitude']], zoom_start=15)\n",
    "            folium.Marker(\n",
    "                location=[best_match_coordinates['latitude'], best_match_coordinates['longitude']],\n",
    "                popup=f\"{most_common_place}\",\n",
    "                icon=folium.Icon(color='green')\n",
    "            ).add_to(m)\n",
    "            display(m)\n",
    "        else:\n",
    "            print(\"Failed to find coordinates for the most common match.\")\n",
    "    else:\n",
    "        print(\"No similar places were found for any images.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
